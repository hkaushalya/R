{
    "contents" : "library(reshape2)\nlibrary(doMC)\nregisterDoMC()\n\n# parameters\ndata.dir    <- './data/'\npatch_size  <- 10\nsearch_size <- 2\n\n\n# read data and convert image strings to arrays\ntrain.file <- paste0(data.dir, 'training.csv')\ntest.file  <- paste0(data.dir, 'test.csv')\ndata.file  <- paste0(data.dir, 'data.Rd')\nd.train    <- read.csv(train.file, stringsAsFactors=F)\nd.test     <- read.csv(test.file,  stringsAsFactors=F)\nim.train   <- foreach(im = d.train$Image, .combine=rbind) %dopar% {\n  as.integer(unlist(strsplit(im, \" \")))\n}\nim.test    <- foreach(im = d.test$Image, .combine=rbind) %dopar% {\n  as.integer(unlist(strsplit(im, \" \")))\n}\nd.train$Image <- NULL\nd.test$Image  <- NULL\n\n\n# list the coordinates we have to predict\ncoordinate.names <- gsub(\"_x\", \"\", names(d.train)[grep(\"_x\", names(d.train))])\n\n\n# for each one, compute the average patch\nmean.patches <- foreach(coord = coordinate.names) %dopar% {\n  cat(sprintf(\"computing mean patch for %s\\n\", coord))\n  coord_x <- paste(coord, \"x\", sep=\"_\")\n  coord_y <- paste(coord, \"y\", sep=\"_\")\n  \n  # compute average patch\n  patches <- foreach (i = 1:nrow(d.train), .combine=rbind) %do% {\n    im  <- matrix(data = im.train[i,], nrow=96, ncol=96)\n    x   <- d.train[i, coord_x]\n    y   <- d.train[i, coord_y]\n    x1  <- (x-patch_size)\n    x2  <- (x+patch_size)\n    y1  <- (y-patch_size)\n    y2  <- (y+patch_size)\n    if ( (!is.na(x)) && (!is.na(y)) && (x1>=1) && (x2<=96) && (y1>=1) && (y2<=96) )\n    {\n      as.vector(im[x1:x2, y1:y2])\n    }\n    else\n    {\n      NULL\n    }\n  }\n  matrix(data = colMeans(patches), nrow=2*patch_size+1, ncol=2*patch_size+1)\n}\n\n# for each coordinate and for each test image, find the position that best correlates with the average patch\np <- foreach(coord_i = 1:length(coordinate.names), .combine=cbind) %dopar% {\n  # the coordinates we want to predict\n  coord   <- coordinate.names[coord_i]\n  coord_x <- paste(coord, \"x\", sep=\"_\")\n  coord_y <- paste(coord, \"y\", sep=\"_\")\n  \n  # the average of them in the training set (our starting point)\n  mean_x  <- mean(d.train[, coord_x], na.rm=T)\n  mean_y  <- mean(d.train[, coord_y], na.rm=T)\n  \n  # search space: 'search_size' pixels centered on the average coordinates \n  x1 <- as.integer(mean_x)-search_size\n  x2 <- as.integer(mean_x)+search_size\n  y1 <- as.integer(mean_y)-search_size\n  y2 <- as.integer(mean_y)+search_size\n  \n  # ensure we only consider patches completely inside the image\n  x1 <- ifelse(x1-patch_size<1,  patch_size+1,  x1)\n  y1 <- ifelse(y1-patch_size<1,  patch_size+1,  y1)\n  x2 <- ifelse(x2+patch_size>96, 96-patch_size, x2)\n  y2 <- ifelse(y2+patch_size>96, 96-patch_size, y2)\n  \n  # build a list of all positions to be tested\n  params <- expand.grid(x = x1:x2, y = y1:y2)\n  \n  # for each image...\n  r <- foreach(i = 1:nrow(d.test), .combine=rbind) %do% {\n    if ((coord_i==1)&&((i %% 100)==0)) { cat(sprintf(\"%d/%d\\n\", i, nrow(d.test))) }\n    im <- matrix(data = im.test[i,], nrow=96, ncol=96)\n    \n    # ... compute a score for each position ...\n    r  <- foreach(j = 1:nrow(params), .combine=rbind) %do% {\n      x     <- params$x[j]\n      y     <- params$y[j]\n      p     <- im[(x-patch_size):(x+patch_size), (y-patch_size):(y+patch_size)]\n      score <- cor(as.vector(p), as.vector(mean.patches[[coord_i]]))\n      score <- ifelse(is.na(score), 0, score)\n      data.frame(x, y, score)\n    }\n    \n    # ... and return the best\n    best <- r[which.max(r$score), c(\"x\", \"y\")]\n  }\n  names(r) <- c(coord_x, coord_y)\n  r\n}\n\n# prepare file for submission\npredictions        <- data.frame(ImageId = 1:nrow(d.test), p)\nsubmission         <- melt(predictions, id.vars=\"ImageId\", variable.name=\"FeatureName\", value.name=\"Location\")\nexample.submission <- read.csv(paste0(data.dir, 'submissionFileFormat.csv'))\nsub.col.names      <- names(example.submission)\nexample.submission$Location <- NULL\n\nsubmission <- merge(example.submission, submission, all.x=T, sort=F)\nsubmission <- submission[, sub.col.names]\n\nwrite.csv(submission, file=\"submission_search.csv\", quote=F, row.names=F)\n",
    "created" : 1383970104229.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2560388811",
    "id" : "D344A9F8",
    "lastKnownWriteTime" : 1383971142,
    "path" : "~/Documents/Personal/Samantha/LearningMaterials/IntroToR/KaggleCompetitions/FacialKeypointsDetection/tutorial.R",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "source_on_save" : false,
    "type" : "r_source"
}